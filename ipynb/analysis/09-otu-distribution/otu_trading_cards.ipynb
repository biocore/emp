{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**author**: lukethompson@gmail.com<br>\n",
    "**date**: 16 Nov 2016<br>\n",
    "**language**: Python 3.5<br>\n",
    "**conda enviroment**: emp-py3<br>\n",
    "**license**: unlicensed<br>\n",
    "\n",
    "## otu_trading_cards.ipynb\n",
    "\n",
    "Generate LaTeX macros and plots for a 'trading card' for any given Deblur OTU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import biom\n",
    "import wikipedia\n",
    "import re\n",
    "import os\n",
    "import errno\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import empcolors\n",
    "import GetV4Region\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# seaborn plot settings\n",
    "sns.set_context('talk')\n",
    "sns.set(style='white', palette='muted', color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "path_map = '~/emp/metadata-refine/emp_qiime_mapping_subset_2k.tsv'\n",
    "path_otus = '~/emp/analyses-otus/otu_summary.emp_deblur_100bp.subset_2k.rare_5000.tsv'\n",
    "path_rdp = '~/emp/analyses-otus/otu_seqs_top_500_prev.emp_deblur_100bp.subset_2k.rare_5000.tsv'\n",
    "obs_column = 'observations_deblur_100bp'\n",
    "trim_length = 100\n",
    "num_samples = 1856 # 2000 for 90bp, 1856 for 100bp, 975 for 150bp\n",
    "rarefaction_depth = 5000\n",
    "subset = '2k'\n",
    "\n",
    "# output\n",
    "path_output = '~/emp/analyses-otus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframe of colors\n",
    "df_colors = pd.DataFrame.from_dict(empcolors.get_empo_cat_color(returndict=True), orient='index')\n",
    "df_colors.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get wikipedia entry for genus or higher (lowest taxonomic level that begins (position 3) with capital letter)\n",
    "def get_wikipedia(my_taxonomy):\n",
    "    for level in reversed(my_taxonomy.split('; ')):\n",
    "        if len(level) > 3:\n",
    "            if level[3].isupper():\n",
    "                title = level[3:]\n",
    "                print(title)\n",
    "                try:\n",
    "                    entry = wikipedia.page(title)\n",
    "                    return('%s\\t%s' % (title, entry.summary))\n",
    "                except wikipedia.exceptions.DisambiguationError as e:\n",
    "                    return('%s\\t%s has multiple options: %s' % (title, title, e.options))\n",
    "                except wikipedia.exceptions.PageError as e:\n",
    "                    return('%s\\t%s has no Wikipedia page.' % (title, title))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make directory if doesn't already exist\n",
    "def make_directory(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise exc\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read mapping file\n",
    "df_map = pd.read_csv(path_map, sep='\\t', index_col=0)\n",
    "# read otu summary\n",
    "df_otus = pd.read_csv(path_otus, sep='\\t', index_col=0)\n",
    "# read rdp taxonomy (index = sequence)\n",
    "df_rdp = pd.read_csv(path_rdp, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Get OTUs matching to query 16S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for path in ['/Users/luke.thompson/moi/RefSeq_16S/Bacteroides_coprocola_M16.NR_041278.fasta',\n",
    "             '/Users/luke.thompson/moi/RefSeq_16S/Bacteroides_dorei_175.NR_041351.fasta',\n",
    "             '/Users/luke.thompson/moi/RefSeq_16S/Bacteroides_intestinalis_341.NR_041307.fasta']:\n",
    "    GetV4Region.GetV4(inputname=path, \n",
    "                  fprimer='GTGCCAGC[AC]GCCGCGGTAA',\n",
    "                  rprimer='ATTAGA[AT]ACCC[CGT][AGT]GTAGTCC',\n",
    "                  length=100,\n",
    "                  remove_ambig=False,\n",
    "                  keep_primers=False,\n",
    "                  skip_reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bacteroides = [\n",
    "        'TACGGAGGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGCAGACGGGAGATTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTG',\n",
    "        'TACGGAGGATCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGATGGATGTTTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTG',\n",
    "        'TACGGAGGATCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGGCGGATTATTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTG',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(bacteroides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_otus_top = df_otus[df_otus['sequence'].isin(bacteroides)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TO DO: Add fasta name to df_otus_top so we can track the strains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Get top OTUs by num_samples OR total_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_otus_top = df_otus.sort_values('num_samples', ascending=False).head(10)\n",
    "df_otus_top = df_otus.sort_values('total_obs', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_otus_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add wikipedia summary\n",
    "df_otus_top['wikipedia'] = df_otus_top['taxonomy'].apply(get_wikipedia)\n",
    "df_otus_top['title'] = [value.split('\\t')[0] for value in df_otus_top['wikipedia']]\n",
    "df_otus_top['wikipedia'] = [value.split('\\t')[1] for value in df_otus_top['wikipedia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index, row in df_otus_top.iterrows():\n",
    "    \n",
    "    # store the relevant values\n",
    "    sequence = row['sequence']\n",
    "    taxonomy_gg = re.sub(r'_', r'\\_', row['taxonomy'])\n",
    "    try:\n",
    "        df_rdp.loc[row['sequence']]\n",
    "        taxonomy_rdp = re.sub(r'_', r'\\_', df_rdp.loc[row['sequence']]['lineage_count'])\n",
    "        species_1st_rdp = df_rdp.loc[row['sequence']]['species_1st_count']\n",
    "        species_2nd_rdp = df_rdp.loc[row['sequence']]['species_2nd_count']\n",
    "        species_3rd_rdp = df_rdp.loc[row['sequence']]['species_3rd_count']\n",
    "    except:\n",
    "        taxonomy_rdp = ''\n",
    "        species_1st_rdp = ''\n",
    "        species_2nd_rdp = ''\n",
    "        species_3rd_rdp = ''\n",
    "    wikipedia = row['wikipedia']\n",
    "    wikipedia = re.sub(r'\"', r'``', wikipedia)\n",
    "    wikipedia = re.sub(u'\\u201D', r\"''\", wikipedia) # need to replace unicode backward double quote\n",
    "    title = row['title']\n",
    "    prevalencePercent = row['num_samples_frac'] * 100\n",
    "    prevalenceRank = str(row['num_samples_rank'] + 1)\n",
    "    abundancePercent = row['total_obs_frac'] * 100\n",
    "    abundanceRank = str(row['total_obs_rank'] + 1)\n",
    "    numOTUs = str(df_otus.shape[0])\n",
    "    trimLength = str(trim_length)\n",
    "    numSamples = str(num_samples)\n",
    "    rarefactionDepth = str(rarefaction_depth)\n",
    "\n",
    "    # MAKE DIRECTORY\n",
    "    make_directory('%s/card_%sbp_subset%s_rare%s_rank%s_%s' % (path_output, \n",
    "            trimLength, subset, rarefactionDepth, prevalenceRank, title))\n",
    "    \n",
    "    # CREATE MACROS FILE\n",
    "    with open('%s/card_%sbp_subset%s_rare%s_rank%s_%s/macros.tex' % (path_output, \n",
    "            trimLength, subset, rarefactionDepth, prevalenceRank, title), 'w') as target:\n",
    "        # SEQUENCE\n",
    "        target.write(r'\\def\\sequence{')\n",
    "        # first 50bp\n",
    "        target.write(sequence[:50])\n",
    "        # next 50bp\n",
    "        target.write('\\n')\n",
    "        target.write(sequence[50:100])\n",
    "        # next 50bp if > 100bp\n",
    "        if len(sequence) > 100:\n",
    "            target.write('\\n')\n",
    "            target.write(sequence[100:150])\n",
    "        target.write('}\\n')\n",
    "        # TAXONOMY\n",
    "        target.write(r'\\def\\taxonomyGG{')\n",
    "        target.write(taxonomy_gg)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\taxonomyRDP{')\n",
    "        target.write(taxonomy_rdp)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\speciesA{')\n",
    "        target.write(species_1st_rdp)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\speciesB{')\n",
    "        target.write(species_2nd_rdp)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\speciesC{')\n",
    "        target.write(species_3rd_rdp)\n",
    "        target.write('}\\n')\n",
    "        # WIKIPEDIA\n",
    "        target.write(r'\\def\\wikipedia{')\n",
    "        if len(wikipedia) > 650:\n",
    "            target.write(wikipedia[:650])\n",
    "            target.write('...')\n",
    "        else:\n",
    "            target.write(wikipedia)\n",
    "        target.write('}\\n')\n",
    "        # PREVALENCE\n",
    "        target.write(r'\\def\\prevalencePercent{')\n",
    "        target.write('{:0.2f}'.format(prevalencePercent))\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\prevalenceRank{')\n",
    "        target.write(prevalenceRank)\n",
    "        target.write('}\\n')\n",
    "        # ABUNDANCE\n",
    "        target.write(r'\\def\\abundancePercent{')\n",
    "        target.write('{:0.3f}'.format(abundancePercent))\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\abundanceRank{')\n",
    "        target.write(abundanceRank)\n",
    "        target.write('}\\n')\n",
    "        # METHODS/MISC\n",
    "        target.write(r'\\def\\numOTUs{')\n",
    "        target.write(numOTUs)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\trimLength{')\n",
    "        target.write(trimLength)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\numSamples{')\n",
    "        target.write(numSamples)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\rarefactionDepth{')\n",
    "        target.write(rarefactionDepth)\n",
    "        target.write('}\\n')\n",
    "        \n",
    "    # EMPO_3 PIE CHART OF PRESENCE/ABSENCE\n",
    "    # value counts of empo_3 categories of samples OTU is found in\n",
    "    empo3_count = df_map.loc[row['list_samples'].split(',')]['empo_3'].value_counts()\n",
    "    # concat colors with counts and then remove zero values\n",
    "    df_empo3 = pd.concat([df_colors, empo3_count], axis=1)\n",
    "    df_empo3.columns = ['color', 'count']\n",
    "    df_empo3_nonzero = df_empo3[df_empo3['count'] > 0]\n",
    "    # draw pie chart\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    fig.set_size_inches(5.6, 3)\n",
    "    patches, text = plt.pie(df_empo3_nonzero['count'], labels=df_empo3_nonzero.index, colors=df_empo3_nonzero['color'], startangle=0)\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('%s/card_%sbp_subset%s_rare%s_rank%s_%s/pie.pdf' % (path_output, \n",
    "            trimLength, subset, rarefactionDepth, prevalenceRank, title))\n",
    "    \n",
    "    # EMPO_3 POINT PLOT OF PRESENCE/ABSENCE\n",
    "    # value counts of empo3 counts in subset of samples\n",
    "    vc_empo3_subset = df_map[df_map['observations_deblur_100bp'] >= 5000]['empo_3'].value_counts()\n",
    "    df_empo3_nonzero.loc[:, 'count_all'] = vc_empo3_subset[df_empo3_nonzero.index] * 0.5\n",
    "    # normalize counts to total\n",
    "    df_empo3_nonzero['count_all_norm'] = df_empo3_nonzero['count_all'] / df_empo3_nonzero['count_all'].sum()\n",
    "    df_empo3_nonzero['count_norm'] = df_empo3_nonzero['count'] / df_empo3_nonzero['count'].sum()\n",
    "    # add empo column and reorder columns\n",
    "    df_empo3_nonzero['empo'] = df_empo3_nonzero.index\n",
    "    df_empo3_nonzero = df_empo3_nonzero[['empo', 'color', 'count_all', 'count', 'count_all_norm', 'count_norm']]\n",
    "    # melt to format that is plot-able\n",
    "    df_empo3_nonzero_melted = pd.melt(df_empo3_nonzero, id_vars=['empo', 'color'], value_vars=['count_norm', 'count_all_norm'])\n",
    "    df_empo3_nonzero_melted.sort_values('variable', ascending=True, inplace=True)\n",
    "    # point plot\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.pointplot(x='variable', y='value', hue='empo', data=df_empo3_nonzero_melted, palette=df_empo3_nonzero_melted['color'])\n",
    "    plt.legend().set_visible(False)\n",
    "    for empo in df_empo3_nonzero.index:\n",
    "        mysize = 8+40*df_empo3_nonzero.loc[empo,'count_norm']\n",
    "        if mysize > 16:\n",
    "            mysize = 16\n",
    "        plt.text(1.08, df_empo3_nonzero.loc[empo,'count_norm'], df_empo3_nonzero.loc[empo,'empo'], fontsize=mysize, va='center')\n",
    "    plt.axis([-0.1, 2.5, -0.01, df_empo3_nonzero['count_norm'].max()*1.1])\n",
    "    plt.box('off')\n",
    "    plt.xticks([0, 1], ('All samples', 'Samples where OTU is found'))\n",
    "    ax.tick_params(labelsize=10)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Relative distribution by EMPO sample type', fontsize=10)\n",
    "    sns.despine(offset=10, trim=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('%s/card_%sbp_subset%s_rare%s_rank%s_%s/point.pdf' % (path_output, \n",
    "        trimLength, subset, rarefactionDepth, prevalenceRank, title))\n",
    "    \n",
    "    # ENVIRONMENTAL PARAMETER DISTRIBUTION PLOTS OF PRESENCE/ABSENCE\n",
    "    # get ph values of samples OTU is found in\n",
    "    ph_values = df_map.loc[row['list_samples'].split(',')]['ph']\n",
    "    ph_values.dropna(inplace=True)\n",
    "    all_ph_values = df_map[df_map[obs_column] >= 5000]['ph']\n",
    "    all_ph_values.dropna(inplace=True)\n",
    "    # get temperature values of samples OTU is found in\n",
    "    temp_values = df_map.loc[row['list_samples'].split(',')]['temperature_deg_c']\n",
    "    temp_values.dropna(inplace=True)\n",
    "    all_temp_values = df_map[df_map[obs_column] >= 5000]['temperature_deg_c']\n",
    "    all_temp_values.dropna(inplace=True)\n",
    "    # get salinity values of samples OTU is found in\n",
    "    sal_values = df_map.loc[row['list_samples'].split(',')]['salinity_psu']\n",
    "    sal_values.dropna(inplace=True)\n",
    "    all_sal_values = df_map[df_map[obs_column] >= 5000]['salinity_psu']\n",
    "    all_sal_values.dropna(inplace=True)\n",
    "    # draw dist plots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(7, 2))\n",
    "    sns.despine(left=True)\n",
    "    # ph\n",
    "    sns.distplot(all_ph_values, hist=False, rug=False, color='0.8', ax=axes[0], kde_kws={\"shade\": True})\n",
    "    if ph_values.shape[0] > 1:\n",
    "        sns.distplot(ph_values, hist=False, rug=True, color='g', ax=axes[0], axlabel='pH', kde_kws={\"shade\": True})\n",
    "    # temp\n",
    "    sns.distplot(all_temp_values, hist=False, rug=False, color='0.8', ax=axes[1], kde_kws={\"shade\": True})\n",
    "    if temp_values.shape[0] > 1:\n",
    "        sns.distplot(temp_values, hist=False, rug=True, color='r', ax=axes[1], axlabel='Temperature (Â°C)', kde_kws={\"shade\": True})\n",
    "    # sal\n",
    "    sns.distplot(all_sal_values, hist=False, rug=False, color='0.8', ax=axes[2], kde_kws={\"shade\": True})\n",
    "    if sal_values.shape[0] > 1:\n",
    "        sns.distplot(sal_values, hist=False, rug=True, color='b', ax=axes[2], axlabel='Salinity (psu)', kde_kws={\"shade\": True})\n",
    "    axes[0].set_xlim([math.floor(all_ph_values.min()), math.ceil(all_ph_values.max())])\n",
    "    axes[1].set_xlim([math.floor(all_temp_values.min()), math.ceil(all_temp_values.max())])\n",
    "    axes[2].set_xlim([math.floor(all_sal_values.min()), math.ceil(all_sal_values.max())])\n",
    "    plt.setp(axes, yticks=[])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('%s/card_%sbp_subset%s_rare%s_rank%s_%s/envparams.pdf' % (path_output, \n",
    "                trimLength, subset, rarefactionDepth, prevalenceRank, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:emp-py3]",
   "language": "python",
   "name": "conda-env-emp-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
