{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## emp500_s3_make_mapping_files_prep_info.ipynb\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook takes a single sample information (metadata) file, a general prep information file, and amplicon target-specific prep information files. It generates a merged prep information file and Qiime mapping file for each amplicon target. A single Qiita study ID will be prepended to sample names when the mega-study goes into Qiita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prep_and_map(df_prep_target, df_prep_general, df_sample, path_prep, path_map):\n",
    "\n",
    "    # merge target-specific and general prep info\n",
    "    prep = pd.merge(df_prep_target, df_prep_general, left_index=True, right_index=True, how='inner')\n",
    "    # rename #SampleID to sample_name\n",
    "    prep.index.names = ['sample_name']\n",
    "    # write prep to tsv\n",
    "    prep.to_csv(path_prep, sep='\\t')\n",
    "\n",
    "    # DROP UNNECESSARY PREP COLUMNS HERE -- sample_name_plus_plate is duplicated in mapping\n",
    "    prep.drop(['sample_name_plus_plate'], axis=1, inplace=True)\n",
    "    \n",
    "    # merge prep info and sample info, add #SampleID and Description column (for Qiime), and write to tsv\n",
    "    mapping = pd.merge(prep, df_sample, left_index=True, right_index=True, how='inner')\n",
    "    mapping.index.names = ['#SampleID']\n",
    "    mapping['Description'] = mapping['sample_name_plus_plate'] + '_' + mapping['primer_name']\n",
    "    mapping.to_csv(path_map, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files: sample information (needs more metadata) and prep information (invariant & target-specific)\n",
    "path_samp_info = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_sample_information.tsv'\n",
    "path_prep_general = '/Users/luke.thompson/emp/500-metadata/input-sample-prep-info/emp500_prep_information_general.xlsx'\n",
    "path_prep_16s1 = '/Users/luke.thompson/emp/500-metadata/input-sample-prep-info/emp500_prep_information_16s_plates1thru5.xlsx'\n",
    "path_prep_16s2 = '/Users/luke.thompson/emp/500-metadata/input-sample-prep-info/emp500_prep_information_16s_plates6thru9.xlsx'\n",
    "path_prep_its1 = '/Users/luke.thompson/emp/500-metadata/input-sample-prep-info/emp500_prep_information_its_plates1thru5.xlsx'\n",
    "path_prep_its2 = '/Users/luke.thompson/emp/500-metadata/input-sample-prep-info/emp500_prep_information_its_plates6thru9.xlsx'\n",
    "path_prep_18s1 = '/Users/luke.thompson/emp/500-metadata/input-sample-prep-info/emp500_prep_information_18s_plates1and5.xlsx'\n",
    "path_prep_18s2 = '/Users/luke.thompson/emp/500-metadata/input-sample-prep-info/emp500_prep_information_18s_plates2thru4.xlsx'\n",
    "\n",
    "# output files: mapping files and prep information files\n",
    "prep_16s1 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_16s_prep_info_plates1thru5.tsv'\n",
    "prep_16s2 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_16s_prep_info_plates6thru9.tsv'\n",
    "prep_its1 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_its_prep_info_plates1thru5.tsv'\n",
    "prep_its2 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_its_prep_info_plates6thru9.tsv'\n",
    "prep_18s1 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_18s_prep_info_plates1and5.tsv'\n",
    "prep_18s2 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_18s_prep_info_plates2thru4.tsv'\n",
    "\n",
    "map_16s1 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_16s_mapping_file_plates1thru5.tsv'\n",
    "map_16s2 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_16s_mapping_file_plates6thru9.tsv'\n",
    "map_its1 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_its_mapping_file_plates1thru5.tsv'\n",
    "map_its2 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_its_mapping_file_plates6thru9.tsv'\n",
    "map_18s1 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_18s_mapping_file_plates1and5.tsv'\n",
    "map_18s2 = '/Users/luke.thompson/emp/500-metadata/output-mapping-prep-info/emp500_18s_mapping_file_plates2thru4.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in files\n",
    "df_samp_info = pd.read_csv(path_samp_info, index_col=0, sep='\\t')\n",
    "df_prep_general = pd.read_excel(path_prep_general, index_col=0)\n",
    "df_prep_16s1 = pd.read_excel(path_prep_16s1, index_col=0)\n",
    "df_prep_16s2 = pd.read_excel(path_prep_16s2, index_col=0)\n",
    "df_prep_its1 = pd.read_excel(path_prep_its1, index_col=0)\n",
    "df_prep_its2 = pd.read_excel(path_prep_its2, index_col=0)\n",
    "df_prep_18s1 = pd.read_excel(path_prep_18s1, index_col=0)\n",
    "df_prep_18s2 = pd.read_excel(path_prep_18s2, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out files\n",
    "generate_prep_and_map(df_prep_target=df_prep_16s1, df_prep_general=df_prep_general, df_sample=df_samp_info,\n",
    "                      path_prep=prep_16s1, path_map=map_16s1)\n",
    "generate_prep_and_map(df_prep_target=df_prep_16s2, df_prep_general=df_prep_general, df_sample=df_samp_info,\n",
    "                      path_prep=prep_16s2, path_map=map_16s2)\n",
    "generate_prep_and_map(df_prep_target=df_prep_its1, df_prep_general=df_prep_general, df_sample=df_samp_info,\n",
    "                      path_prep=prep_its1, path_map=map_its1)\n",
    "generate_prep_and_map(df_prep_target=df_prep_its2, df_prep_general=df_prep_general, df_sample=df_samp_info,\n",
    "                      path_prep=prep_its2, path_map=map_its2)\n",
    "generate_prep_and_map(df_prep_target=df_prep_18s1, df_prep_general=df_prep_general, df_sample=df_samp_info,\n",
    "                      path_prep=prep_18s1, path_map=map_18s1)\n",
    "generate_prep_and_map(df_prep_target=df_prep_18s2, df_prep_general=df_prep_general, df_sample=df_samp_info,\n",
    "                      path_prep=prep_18s2, path_map=map_18s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
